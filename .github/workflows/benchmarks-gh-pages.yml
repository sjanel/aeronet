name: Benchmarks and GitHub pages Sync

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  # Weekly scheduled run on main to produce more stable benchmark results
  schedule:
    - cron: '0 3 * * 0'  # every Sunday at 03:00 UTC
  # Allow manual runs via the Actions UI with an optional duration override
  workflow_dispatch:
    inputs:
      bench_duration:
        description: 'Benchmark duration (e.g. 90s)'
        required: false
        default: '90s'

permissions:
  contents: write

jobs:
  # ------------------------------------------------------------------ #
  # Bench: two parallel runs with different wrk connection counts.      #
  # Both use GCC; low connections measures latency accurately, high     #
  # connections stresses max throughput.                                 #
  # ------------------------------------------------------------------ #
  bench:
    name: Bench (${{ matrix.conn_label }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          # Low connections: 10/thread - accurate latency, moderate throughput
          - compiler: gcc-13
            conn_label: low
            connections_per_thread: 10
          # High connections: 50/thread - higher throughput, higher latency
          - compiler: gcc-13
            conn_label: high
            connections_per_thread: 100
    steps:
      - name: Checkout current main
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Install all dependencies with features
        run: |
          sudo apt update
          sudo apt install -y wrk libjsoncpp-dev uuid-dev libssl-dev libcurl4-openssl-dev
          pip install uvicorn starlette

      - name: Install GCC toolchain
        if: ${{ startsWith(matrix.compiler, 'gcc') }}        
        run: sudo apt-get install -y ${{ matrix.compiler }}

      - name: Install Clang/LLVM toolchain
        if: ${{ startsWith(matrix.compiler, 'clang') }}
        run: |
            wget --retry-connrefused --waitretry=5 --tries=5 https://apt.llvm.org/llvm.sh
            chmod +x llvm.sh
            compiler="${{ matrix.compiler }}"
            version="${compiler##*-}"
            echo "Detected clang version: $version"
            sudo ./llvm.sh "$version"
            sudo apt-get install -y "lld-$version"

      - name: Set compiler environment
        run: |
          compiler="${{ matrix.compiler }}"
          echo "CC=$compiler" >> $GITHUB_ENV
          ver="${compiler##*-}"
          if [[ "$compiler" == gcc-* ]]; then
            echo "CXX=g++-$ver" >> $GITHUB_ENV
          else
            echo "CXX=clang++-$ver" >> $GITHUB_ENV
          fi
          echo "Derived compilers: CC=$compiler CXX set for version $ver"

      - name: Show compiler version
        run: |
          $CXX --version

      - name: Configure benchmark build
        run: |
          ./scripts/retry.sh cmake -S . -B build-pages -G Ninja \
            -DCMAKE_BUILD_TYPE=Release \
            -DAERONET_BUILD_TESTS=OFF \
            -DAERONET_BUILD_EXAMPLES=OFF \
            -DAERONET_BUILD_BENCHMARKS=ON \
            -DAERONET_ENABLE_ASAN=OFF \
            -DAERONET_ENABLE_CLANG_TIDY=OFF \
            -DAERONET_ENABLE_SPDLOG=ON \
            -DAERONET_ENABLE_OPENSSL=ON \
            -DAERONET_ENABLE_HTTP2=ON \
            -DAERONET_ENABLE_BROTLI=ON \
            -DAERONET_ENABLE_ZLIB=ON \
            -DAERONET_ENABLE_ZSTD=ON \
            -DAERONET_ENABLE_OPENTELEMETRY=OFF \
            -DAERONET_ENABLE_WEBSOCKET=ON \
            -DAERONET_ENABLE_ASYNC_HANDLERS=ON

      - name: Build
        run: |
          cmake --build build-pages --parallel

      - name: Run benchmarks
        working-directory: ${{github.workspace}}/build-pages/benchmarks/scripted-servers
        run: |
          # Decide duration and threads based on event type and inputs.
          # Defaults:
          #  - pull_request / non-main push => 5s, 1 thread (fast)
          #  - push to main => 30s, 2 threads
          #  - schedule or workflow_dispatch => use workflow input (or default 90s), 2 threads

          EVENT_NAME=${GITHUB_EVENT_NAME:-}
          REF=${GITHUB_REF:-}
          WARMUP=5s
          THREADS=2
          CPT=${{ matrix.connections_per_thread }}
          CONN=$((THREADS * CPT))

          if [ "$EVENT_NAME" = "push" ] && [ "$REF" = "refs/heads/main" ]; then
            DUR=30s
          elif [ "$EVENT_NAME" = "workflow_dispatch" ] || [ "$EVENT_NAME" = "schedule" ]; then
            if [ -n "${{ github.event.inputs.bench_duration }}" ]; then
              DUR="${{ github.event.inputs.bench_duration }}"
            else
              DUR=90s
            fi
          else
            # pull_request and non-main pushes
            DUR=5s
            WARMUP=2s
            THREADS=1
            CONN=$((THREADS * CPT))
          fi

          echo "Event: $EVENT_NAME ref: $REF -> $DUR, $THREADS threads, $CONN connections ($CPT/thread)"

          BENCH_WRK_TIMEOUT=${BENCH_WRK_TIMEOUT:-10s}
          BODY_CODEC_MAX_PAYLOAD_KB=${BODY_CODEC_MAX_PAYLOAD_KB:-4096}
          export BENCH_WRK_TIMEOUT BODY_CODEC_MAX_PAYLOAD_KB
          echo "Using BENCH_WRK_TIMEOUT=$BENCH_WRK_TIMEOUT BODY_CODEC_MAX_PAYLOAD_KB=$BODY_CODEC_MAX_PAYLOAD_KB"

          ./run_benchmarks.py --duration "$DUR" --threads "$THREADS" --warmup "$WARMUP" --connections "$CONN"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        with:
          name: bench-results-${{ matrix.conn_label }}
          path: build-pages/benchmarks/scripted-servers/results/benchmark_latest.json
          retention-days: 3

      - name: Upload badge (high-connections run only)
        if: matrix.conn_label == 'high'
        uses: actions/upload-artifact@v6
        with:
          name: bench-badge
          path: build-pages/benchmarks/scripted-servers/results/benchmark_badge.json
          retention-days: 3
          if-no-files-found: ignore

  # ------------------------------------------------------------------ #
  # Publish: aggregate both benchmark results and deploy to gh-pages.   #
  # ------------------------------------------------------------------ #
  publish:
    name: Publish Pages
    runs-on: ubuntu-latest
    needs: bench
    if: always() && !cancelled()
    steps:
      - name: Checkout current main
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Configure git identity for runner
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Assemble site content from main
        run: |
          rm -rf /tmp/site
          mkdir -p /tmp/site
          rsync -a docs/ /tmp/site/docs/
          rsync -a resources/ /tmp/site/resources/
          cp README.md /tmp/site/index.md

      - name: Download all benchmark results
        uses: actions/download-artifact@v7
        with:
          path: /tmp/bench-artifacts

      - name: Render HTML for Pages
        run: |
          rm -fr /tmp/site/benchmarks
          mkdir -p /tmp/site/benchmarks

          # Collect all result JSONs found across matrix runs
          INPUTS=()
          for label in low high; do
            json="/tmp/bench-artifacts/bench-results-${label}/benchmark_latest.json"
            if [[ -f "$json" ]]; then
              INPUTS+=("--input" "$json")
              # Also copy each JSON for raw access
              cp "$json" "/tmp/site/benchmarks/benchmark_${label}.json"
            fi
          done

          if [[ ${#INPUTS[@]} -eq 0 ]]; then
            echo "WARNING: No benchmark results found; skipping render"
            exit 0
          fi

          benchmarks/scripted-servers/render_benchmarks_html.py \
            "${INPUTS[@]}" \
            --output /tmp/site/benchmarks/index.html

          # Copy badge if available
          if [[ -f /tmp/bench-artifacts/bench-badge/benchmark_badge.json ]]; then
            cp /tmp/bench-artifacts/bench-badge/benchmark_badge.json /tmp/site/benchmarks/benchmark_badge.json
          fi

      - name: Publish site snapshot to gh-pages
        if: ${{ github.event_name != 'pull_request' }}
        run: |
          set -euo pipefail
          REPO="https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}"

          rm -rf /tmp/gh
          mkdir -p /tmp/gh

          # Populate the workspace with the snapshot from /tmp/site, then initialize git
          rsync -a --delete /tmp/site/ /tmp/gh/ || ( echo "rsync failed" && exit 1 )

          git -C /tmp/gh init
          git -C /tmp/gh checkout -b gh-pages || true
          git -C /tmp/gh add --all
          git -C /tmp/gh commit --allow-empty -m "Site snapshot from ${GITHUB_SHA}"
          # Ensure origin remote exists so lease can be compared correctly
          git -C /tmp/gh remote add origin "$REPO" || true
          # Try fetching remote gh-pages to populate refs for --force-with-lease; ignore failure if branch doesn't exist
          git -C /tmp/gh fetch --no-tags --depth=1 origin gh-pages || true
          # Push HEAD to gh-pages using --force-with-lease to avoid clobbering concurrent updates
          git -C /tmp/gh push --force-with-lease origin HEAD:gh-pages
